{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9196082f-1d4c-453d-9c1d-15152e9eb6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/mamba/envs/ast-finetune/lib/python3.7/site-packages/torch/cuda/amp/autocast_mode.py:118: UserWarning: torch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.autocast only affects CUDA ops, but CUDA is not available.  Disabling.\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from models.ast_model import ASTModel\n",
    "import numpy as np\n",
    "import os\n",
    "import torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d30e2ca-1efe-4eff-8db4-3e40c7eb4875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model,optimizer,training_loader,loss_fn):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    # Here, we use enumerate(training_loader) instead of\n",
    "    # iter(training_loader) so that we can track the batch\n",
    "    # index and do some intra-epoch reporting\n",
    "    for i, data in enumerate(training_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 1000 == 999:\n",
    "            last_loss = running_loss / 1000 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            #tb_x = epoch_index * len(training_loader) + i + 1\n",
    "            #tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01d62c0b-7656-49f6-961a-1be9747028e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch_nb, training_loader, validation_loader, model, optimizer, loss_fn, scheduler):\n",
    "    best_vloss = 1_000_000.\n",
    "\n",
    "    for epoch in range(epoch_nb):\n",
    "        print('EPOCH {}:'.format(epoch + 1))\n",
    "    \n",
    "        # Make sure gradient tracking is on, and do a pass over the data\n",
    "        model.train(True)\n",
    "        avg_loss = train_one_epoch(model,optimizer,training_loader,loss_fn)\n",
    "    \n",
    "    \n",
    "        running_vloss = 0.0\n",
    "        # Set the model to evaluation mode, disabling dropout and using population\n",
    "        # statistics for batch normalization.\n",
    "        model.eval()\n",
    "    \n",
    "        # Disable gradient computation and reduce memory consumption.\n",
    "        with torch.no_grad():\n",
    "            for i, vdata in enumerate(validation_loader):\n",
    "                vinputs, vlabels = vdata\n",
    "                voutputs = model(vinputs)\n",
    "                vloss = loss_fn(voutputs, vlabels)\n",
    "                running_vloss += vloss\n",
    "    \n",
    "        avg_vloss = running_vloss / (i + 1)\n",
    "        print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "    \n",
    "        # Log the running loss averaged per batch\n",
    "        # for both training and validation\n",
    "        #writer.add_scalars('Training vs. Validation Loss',\n",
    "                        #{ 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                       # epoch_number + 1)\n",
    "        #writer.flush()\n",
    "    \n",
    "        # Track best performance, and save the model's state\n",
    "        if avg_vloss < best_vloss:\n",
    "            best_vloss = avg_vloss\n",
    "            print('Best model found at epoch: ' + str(epoch))\n",
    "        model_path = 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "141e22c0-7325-471c-8c7f-bc19eeb457f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AST_multichannel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AST_multichannel,self).__init__()\n",
    "        self.ast = ASTModel(audioset_pretrain=True)\n",
    "        idt = torch.nn.Identity()\n",
    "        for i in range(5,12):\n",
    "            self.ast.v.blocks[i] = idt\n",
    "        self.ast.v.mlp_head = idt\n",
    "        self.lin1 = torch.nn.Linear(768*4, 768)\n",
    "        self.lin2 = torch.nn.Linear(768, 128)\n",
    "        self.lin3 = torch.nn.Linear(128,2)\n",
    "        self.act = torch.nn.ReLU()\n",
    "        self.sig = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.ast(x[:,0])\n",
    "        x2 = self.ast(x[:,1])\n",
    "        x3 = self.ast(x[:,2])\n",
    "        x4 = self.ast(x[:,3])\n",
    "        x = torch.cat((x1,x2,x3,x4),axis=1)\n",
    "        x = self.act(self.lin1(x))\n",
    "        x = self.act(self.lin2(x))\n",
    "        x = self.sig(self.lin3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6f1973b-9c6c-4d49-be09-ea93909bbd28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Centroid:\n",
      "(1000, 2)\n",
      "Shape of RIRs:\n",
      "(1000, 4, 667200)\n"
     ]
    }
   ],
   "source": [
    "DATASET_PATH = \"LivingRoom_preprocessed_hack/Human1\"\n",
    "\n",
    "centroid = np.load(os.path.join(DATASET_PATH, \"centroid.npy\"))\n",
    "print(\"Shape of Centroid:\")\n",
    "print(centroid.shape)\n",
    "\n",
    "#Loading Room Impulse Response (1000 human locations x 10 microphones x M time samples)\n",
    "RIRs = np.load(os.path.join(DATASET_PATH, \"deconvoled_trim.npy\"), mmap_mode='r')\n",
    "print(\"Shape of RIRs:\")\n",
    "print(RIRs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3d0adef7-1309-4321-8a98-6178c0fcff4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/mamba/envs/ast-finetune/lib/python3.7/site-packages/torchaudio/functional/functional.py:358: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  \"At least one mel filterbank has all zero values. \"\n"
     ]
    }
   ],
   "source": [
    "spec = torchaudio.transforms.MelSpectrogram(48000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "660af1a5-34a7-4463-8b87-2317bc8322fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = torch.tensor(RIRs)\n",
    "X_all = torch.stack([spec(audio[:,0]),spec(audio[:,1]),spec(audio[:,2]),spec(audio[:,3])],dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cce29b5-760d-47d8-a7e3-ab7c71472e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9133f064-9d3f-4c34-9cef-8e441d57bde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RIRDataset(Dataset):\n",
    "    def __init__(self, specs, centroids):\n",
    "        self.specs = specs\n",
    "        self.centroids = centroids\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.specs.shape[0]\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        return (self.specs[idx],self.centroids[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c1cbb80-54a4-42a9-8795-b6263cabee24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 4, 128, 3337])\n",
      "torch.Size([1000, 2])\n"
     ]
    }
   ],
   "source": [
    "print(X_all.shape)\n",
    "Y_all = torch.tensor(centroid)\n",
    "print(Y_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "053e366f-a768-494f-9a80-4d9fc182567c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------AST Model Summary---------------\n",
      "ImageNet pretraining: True, AudioSet pretraining: True\n",
      "frequncey stride=10, time stride=10\n",
      "number of patches=3996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/mamba/envs/ast-finetune/lib/python3.7/site-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode)\n"
     ]
    }
   ],
   "source": [
    "model = AST_multichannel()\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "scheduler=None\n",
    "\n",
    "train_set = RIRDataset(X_all[:800],Y_all[:800])\n",
    "valid_set = RIRDataset(X_all[800:],Y_all[800:])\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=32, shuffle=True)\n",
    "valid_loader = DataLoader(valid_set, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45463f2-4f21-429f-9af5-695e37f666be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n"
     ]
    }
   ],
   "source": [
    "train(15,train_loader,valid_loader,model,optim,loss_fn,scheduler)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ast_env",
   "language": "python",
   "name": "ast_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
